Exploring Representation Learning with CNNs for Frame to Frame Ego-Motion Estimation
 
意大利佩鲁贾大学
介绍
  使用端到端的深度神经网络来实现视觉里程计。
目前的视觉里程计方法主要分以下几种：
1)	几何方法：基于特征的方法。通过对每张照片提取视觉显著点，并在连续的图片中进行跟踪，使用三角测量重建每个点的3D位姿。通常需要从其他传感器中获得额外的传感器信息，并利用回环检测来恢复尺度误差。该方法缺点是尺度误差会累积，在特征不是很明显的时候就会失败，例如低纹理或模糊的图片。时间和场景都会随光照变化，动态物体的存在，不同的相机标定。
2)	几何方法：基于稠密点的方法。直接使用整个图片来代替，类似于稠密光流提取，但并不是提取每个像素点的移动，而是提取潜在相机的移动。优点是可以获得比特征方法更精确的结果，但是计算量很大，很难达到实时性。
3)	学习的方法：基于几何的方法有强假定：从图片中提取什么信息，怎么去使用信息来计算位移，而学习的方法则是从数据中推断出来。
本文的贡献：
使用不同的CNN结构探索ego-motion估计的特征选择，CNN提取的特征很健壮，不会受到不同图片对比度和模糊的影响。效果要比一些几何方法和学习方法好。
